{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9da014d0-9a02-43d7-b25e-86e547124407",
   "metadata": {},
   "source": [
    "# Final Project: Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95703485-f5c4-448c-974c-c7586557b04e",
   "metadata": {},
   "source": [
    "## Name: <span style=\"color:blue\"> *Josiah Hemphill* </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39a01fb-0f3a-4039-9c6e-008028744072",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad763d5f-330d-479f-860d-82b1eb7473cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple, Callable\n",
    "import os\n",
    "import gc\n",
    "import traceback\n",
    "import warnings\n",
    "from pdb import set_trace\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a195b946-4606-4beb-a41a-5b9b71e05e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "148daa44-c9f3-4ba0-9c10-10f81b3ba483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "vgsales_df = pd.read_csv(\"vgsales.csv\")\n",
    "feature_names = vgsales_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a61c809-9626-4a06-b995-015b5f625412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_classes(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    pos_class: List[int], \n",
    "    neg_class: List[int]\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\" Converts data into a one-vs-all or one-vs-one prolbem\n",
    "        according to labels passed as pos or neg.\n",
    "\n",
    "        Args:\n",
    "            X: Input data given as matrix\n",
    "\n",
    "            y: Labels corresponding to input data given as 1D vector\n",
    "\n",
    "            pos_class: list of labels that will be used for \n",
    "                the positive class.\n",
    "\n",
    "            neg_class: list of labels that will be used for \n",
    "                the negative class.\n",
    "\n",
    "        Returns:\n",
    "            Two arrays where the 1st corresponds to the data\n",
    "            given as a matrix and the 2nd corresponds to the\n",
    "            new labels given as a 1D vector.\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "    y = y.copy()\n",
    "    \n",
    "    # TODO 2.1\n",
    "    X_pos, y_pos = None, None\n",
    "    pos_locs = np.isin(y, pos_class)\n",
    "    X_pos = X[pos_locs]\n",
    "    y_pos = y[pos_locs]\n",
    "    y_pos[:] = 1\n",
    "    \n",
    "    # TODO 2.2\n",
    "    X_neg, y_neg = None, None\n",
    "    neg_locs = np.isin(y, neg_class)\n",
    "    X_neg = X[neg_locs]\n",
    "    y_neg = y[neg_locs]\n",
    "    y_neg[:] = -1\n",
    "    \n",
    "    return np.vstack([X_pos, X_neg]), np.hstack([y_pos, y_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d88f248c-6739-4a21-8e35-0bd0d97b87d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def get_train_valid_test_data(\n",
    "    X: np.ndarray, \n",
    "    y: np.ndarray, \n",
    "):\n",
    "    \"\"\" Randomizes and then splits the data into train, validation, and test sets.\n",
    "\n",
    "        Args:\n",
    "            X: Data given as a 2D matrix\n",
    "\n",
    "            y: Labels given as a vector \n",
    "    \"\"\"\n",
    "    X_trn, X_tst, y_trn, y_tst = train_test_split(X, y, train_size=.8, random_state=42)\n",
    "    X_trn, X_vld, y_trn, y_vld = train_test_split(X_trn, y_trn, train_size=.8, random_state=42)\n",
    "\n",
    "    return X_trn, y_trn, X_vld, y_vld, X_tst, y_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7db10bff-211b-4da1-bfd8-ec8edb922599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "def get_preprocessed_data(pos_class: List[int], neg_class: List[int])  -> Tuple[np.ndarray]:\n",
    "    \"\"\" Gets preprocessed data for training, validation, and testing\n",
    "\n",
    "        Args:\n",
    "            pos_class: list of labels that will be used for \n",
    "                the positive class.\n",
    "\n",
    "            neg_class: list of labels that will be used for \n",
    "                the negative class.\n",
    "\n",
    "        Return:\n",
    "            A tuple of NumPy arrays where indices 0-1 \n",
    "            contain the training data/targets, indices 2-3\n",
    "            contain the validation data/targets, and 4-5\n",
    "            contain the testing data/targets.\n",
    "    \"\"\"\n",
    "    # TODO 3.1\n",
    "    X, y = binarize_classes(iris.data.values, iris.target.values, pos_class, neg_class)\n",
    "    \n",
    "    # TODO 3.2\n",
    "    X_trn, y_trn, X_vld, y_vld, X_tst, y_tst= get_train_valid_test_data(X, y)\n",
    "    \n",
    "\n",
    "    # TODO 3.3\n",
    "    scaler.fit(X_trn)\n",
    "    X_trn = scaler.transform(X_trn)\n",
    "    X_vld = scaler.transform(X_vld)\n",
    "    X_tst = scaler.transform(X_tst)\n",
    "    \n",
    "    # TODO 3.4\n",
    "    m_samples = len(X_trn)\n",
    "    bias = np.ones((m_samples, 1))\n",
    "    X_trn = np.hstack([bias, X_trn])\n",
    "\n",
    "    m_samples = len(X_tst)\n",
    "    bias = np.ones((m_samples, 1))\n",
    "    X_tst = np.hstack([bias, X_tst])\n",
    "\n",
    "    m_samples = len(X_vld)\n",
    "    bias = np.ones((m_samples, 1))\n",
    "    X_vld = np.hstack([bias, X_vld])\n",
    "    \n",
    "\n",
    "    # Reshape targets to be 2D column vectors\n",
    "    return X_trn, y_trn.reshape(-1, 1), X_vld, y_vld.reshape(-1, 1), X_tst, y_tst.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a25eb210-cc64-47d3-95e8-b2b6255e9e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y: np.ndarray, y_hat: np.ndarray) -> float:\n",
    "    \"\"\" Computes the accuracy between two 1D vectors\n",
    "\n",
    "        Args:\n",
    "            y: Ground truth labels given as a 1D vector\n",
    "\n",
    "            y_hat: Predicted labels given as a 1D vector\n",
    "\n",
    "        Return:\n",
    "            A float corresponding to the accuracy\n",
    "    \"\"\"\n",
    "    y =  y.flatten() # reshape to make 1D vector for consistency\n",
    "    y_hat = y_hat.flatten() # reshape to make 1D vector for consistency\n",
    "\n",
    "    # TODO 4\n",
    "    y_hat == y\n",
    "    total_correct = np.sum(y_hat == y)\n",
    "    accuracy = total_correct / len(y)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9db58fa6-b510-4801-b752-592a86add55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(\n",
    "    y: np.ndarray, \n",
    "    y_hat: np.ndarray, \n",
    "    class_name_key: Dict[int, str] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\" Plots a pretty and labeld version of Sklerarn's confusion matrix\n",
    "\n",
    "        Args:\n",
    "            y: Ground truth labels given as a 1D vector\n",
    "\n",
    "            y_hat: Predicted labels given as a 1D vector\n",
    "\n",
    "            class_name_key: A dictionary where each key corresponds to \n",
    "                a label in y and the values corresponding to string name \n",
    "                for said label. This name will be displayed when plotting.\n",
    "\n",
    "        Returns:\n",
    "            A confusion matrix casted as a DataFrame\n",
    "    \"\"\"\n",
    "    y =  y.flatten() # reshape to make 1D vector for consistency\n",
    "    y_hat = y_hat.flatten() # reshape to make 1D vector for consistency\n",
    "    \n",
    "    # TODO 5\n",
    "    cfm = confusion_matrix(y, y_hat)\n",
    "    \n",
    "    \n",
    "    labels = np.sort(np.unique(y))\n",
    "    if class_name_key is not None:\n",
    "        classes = []\n",
    "        for l in labels:\n",
    "            class_name = class_name_key.get(l, l)\n",
    "            classes.append(class_name)\n",
    "        labels = classes\n",
    "        \n",
    "    columns, index = labels, labels\n",
    "    cfm_df = pd.DataFrame(cfm, index=index, columns=columns)\n",
    "    sns.heatmap(cfm_df, annot=True)\n",
    "\n",
    "    return cfm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd5a02c5-1f9a-4820-a347-3e49affaf467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppv(y: np.ndarray, y_hat: np.ndarray) -> float:\n",
    "    \"\"\" Compute the PPV or precision score\n",
    "\n",
    "        Args:\n",
    "            y: Ground truth labels given as a 1D vector\n",
    "\n",
    "            y_hat: Predicted labels given as a 1D vector\n",
    "\n",
    "        Returns:\n",
    "            A float corresponding to the PPV value.\n",
    "    \"\"\"\n",
    "    y =  y.flatten() # reshape to make 1D vector for consistency\n",
    "    y_hat = y_hat.flatten() # reshape to make 1D vector for consistency\n",
    "    \n",
    "    # TODO 6\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_hat).ravel()\n",
    "    ppv = tp / (tp + fp)\n",
    "    return ppv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "159bf1a0-9955-4bc1-a042-8d6cf81772e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr(y: np.ndarray, y_hat: np.ndarray) -> float:\n",
    "    \"\"\" Compute the TPR or recall score\n",
    "\n",
    "        Args:\n",
    "            y: Ground truth labels given as a 1D vector\n",
    "\n",
    "            y_hat: Predicted labels given as a 1D vector\n",
    "\n",
    "        Returns:\n",
    "            A float corresponding to the TPR value.\n",
    "    \"\"\"\n",
    "    # TODO 7\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_hat).ravel()\n",
    "    tpr = tp / (tp + fn)\n",
    "    return tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a9a31ac-c76e-4768-a26b-0e2c2e0f9178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnr(y: np.ndarray, y_hat: np.ndarray) -> float:\n",
    "    \"\"\" Compute the TNR or specificity score\n",
    "\n",
    "        Args:\n",
    "            y: Ground truth labels given as a 1D vector\n",
    "\n",
    "            y_hat: Predicted labels given as a 1D vector\n",
    "\n",
    "        Returns:\n",
    "            A float corresponding to the TNR value.\n",
    "    \"\"\"\n",
    "    # TODO 8\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_hat).ravel()\n",
    "    tnr = tn / (tn + fp)\n",
    "    return tnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccbe2514-4208-4618-a2cb-7f5cbad6a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    \"\"\" Performs binary classification using Rosenblatt's perceptron\n",
    "    \n",
    "        Attributes:\n",
    "\n",
    "            alpha: learning rate or step size\n",
    " \n",
    "            epochs: Number of epochs to run for mini-batch\n",
    "                gradient descent\n",
    "                \n",
    "            seed: Seed to be used for NumPy's RandomState class\n",
    "                or universal seed np.random.seed() function.\n",
    "\n",
    "            w: Vector of weights \n",
    "\n",
    "            trn_acc: List that stores training accuracy for each epoch.\n",
    "\n",
    "            vld_acc: List that stores validation accuracy for each epoch.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        alpha: float,\n",
    "        seed: int = 0,\n",
    "        epochs: int = 1,\n",
    "    ):\n",
    "        self.alpha = alpha\n",
    "        self.epochs = epochs\n",
    "        self.seed = seed\n",
    "        self.w = None\n",
    "        self.trn_acc = None\n",
    "        self.vld_acc = None\n",
    "\n",
    "    def fit(\n",
    "         self, X: np.ndarray, \n",
    "         y: np.ndarray, \n",
    "         X_vld: np.ndarray=None, \n",
    "         y_vld: np.ndarray=None\n",
    "     ) -> object:\n",
    "        \"\"\" Train the perceptron to find optimal weights\n",
    "\n",
    "            Args:\n",
    "                X: Training data given as a 2D matrix\n",
    "\n",
    "                y: Training labels given as a 2D column vector\n",
    "                \n",
    "            Returns:\n",
    "                The class's own object reference. \n",
    "        \"\"\"\n",
    "        np.random.seed(self.seed) # Set seed for reproducibility\n",
    "        self.trn_acc = []\n",
    "        self.vld_acc = []\n",
    "        # TODO 9.1 - 9.2\n",
    "        self.w = np.random.rand(X.shape[1])\n",
    "        for e in range(self.epochs):\n",
    "            misclassified = 0\n",
    "            for m in range(X.shape[0]):\n",
    "                z = X[m].T @ self.w\n",
    "                y_hat = np.sign(z)\n",
    "                if (y_hat != y[m]):\n",
    "                    misclassified += 1\n",
    "                    self.w = self.w + self.alpha * y[m] * X[m]\n",
    "            \n",
    "            trn_preds = self.predict(X)\n",
    "            trn_acc = accuracy(y, trn_preds)\n",
    "            self.trn_acc.append(trn_acc)\n",
    "\n",
    "            if X_vld is not None and y_vld is not None:\n",
    "                vld_preds = self.predict(X_vld)\n",
    "                vld_acc = accuracy(y_vld, vld_preds)\n",
    "                self.vld_acc.append(vld_acc)\n",
    "            \n",
    "            if (misclassified == 0):\n",
    "                break\n",
    "        return self \n",
    "        \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Make predictions using learned weights\n",
    "\n",
    "            Args:\n",
    "                X: Testing data given as a 2D matrix\n",
    "\n",
    "            Returns:\n",
    "                A 2D column vector of predictions for each data sample in X\n",
    "        \"\"\"\n",
    "        # TODO 9.3\n",
    "        y_hat = np.sign(X @ self.w)\n",
    "        return y_hat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
